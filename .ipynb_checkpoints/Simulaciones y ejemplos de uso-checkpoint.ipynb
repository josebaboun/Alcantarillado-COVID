{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.Funciones_basicas import *\n",
    "from ipynb.fs.full.Algoritmos import *\n",
    "from ipynb.fs.full.Visualizaciones import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplos de uso\n",
    "## Instanciar el grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/graph_geom_corrected_cycles.csv'\n",
    "csv_grafo = pd.read_csv(path, sep = ';')\n",
    "geometry = gpd.read_file(path, GEOM_POSSIBLE_NAMES=\"geometry\", KEEP_GEOM_COLUMNS=\"NO\")\n",
    "path_pesos = 'data/pesos_tapas.csv'\n",
    "pesos = pd.read_csv(path_pesos)\n",
    "\n",
    "S = set()\n",
    "for index, row in csv_grafo.iterrows():\n",
    "    origin = row['self']\n",
    "    dest = row['other']\n",
    "    S.add(origin)\n",
    "    S.add(dest)\n",
    "\n",
    "S = list(S)\n",
    "id_ = {}; _id = {}; l = 0\n",
    "for u in S:\n",
    "    id_[u] = l; _id[l] = u\n",
    "    l += 1\n",
    "\n",
    "G = nx.DiGraph()\n",
    "for index, row in csv_grafo.iterrows():\n",
    "    origin = row['self']\n",
    "    dest = row['other']\n",
    "    G.add_edge(id_[origin], id_[dest])\n",
    "    \n",
    "N = l\n",
    "\n",
    "W = [0 for u in range(N)]\n",
    "V = [0 for u in range(N)]\n",
    "\n",
    "for u in range(N):\n",
    "    if pesos[pesos['ID_tapa'] == _id[u]].shape[0] >= 1:  ## tomamos primera columna con el id, si no hay peso = 0\n",
    "        W[u] = pesos[pesos['ID_tapa'] == _id[u]].iloc[0]['per_predio']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algunos ejemplos de uso de códigos para obtener y visualizar resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Máximo de nodos por ideal: 460.3\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a97689a8798b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmax_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Máximo de nodos por ideal: {max_nodes}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgreedyAppW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplot_solution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeometry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Alcantarillado-COVID/Algoritmos.ipynb\u001b[0m in \u001b[0;36mgreedyAppW\u001b[0;34m(G, V_, N, K, limit, wlim)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;34m\"    \\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;34m\"    V = V_.copy()\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0;34m\"    #V = V_\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0;34m\"    \\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;34m\"    E = []\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Alcantarillado-COVID/Funciones_basicas.ipynb\u001b[0m in \u001b[0;36mget_size_weight\u001b[0;34m(G, W, V_, u)\u001b[0m\n\u001b[1;32m     65\u001b[0m    ]\n\u001b[1;32m     66\u001b[0m   },\n\u001b[0;32m---> 67\u001b[0;31m   {\n\u001b[0m\u001b[1;32m     68\u001b[0m    \u001b[0;34m\"cell_type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"markdown\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m    \u001b[0;34m\"metadata\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'copy'"
     ]
    }
   ],
   "source": [
    "V = [0 for u in range(N)]\n",
    "max_nodes = len(G.nodes)/10\n",
    "print(f'Máximo de nodos por ideal: {max_nodes}')\n",
    "ans = greedyAppW(G, V, N, 10, max_nodes, 200000)\n",
    "plot_solution(ans, G, N, geometry, _id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K = 13\n",
    "# nodes_limit = 800\n",
    "# weight_limit = 10e8\n",
    "# G_ = G.copy()\n",
    "# nodos_inicial = len(G_.nodes())\n",
    "# salida = id_[1001544]\n",
    "\n",
    "# V = [0] * N\n",
    "\n",
    "# low = 0; high = N\n",
    "# while low != high:\n",
    "#     mid = (low + high) // 2\n",
    "#     P, sP = greedyAppWeightReduceDynamic(G, V, N, K, mid, 100000000)\n",
    "#     if N - sP < mid:\n",
    "#         high = mid\n",
    "#     else:\n",
    "#         low = mid + 1\n",
    "\n",
    "# low -= 1\n",
    "\n",
    "\n",
    "# sample, sP = greedyAppWeightReduceDynamic(G, V, N, K, low, 100000000)\n",
    "\n",
    "# print(low, N - sP)\n",
    "# print(len(sample))  ## if less than 8 entire graph gets covered with less samples\n",
    "\n",
    "# plot_sample_no_intersections(G, V, N, sample, geometry.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = [0] * N\n",
    "ans, sol_dict, sizes, sol_ideals = greedyAppWeightReduceDynamic_partition(G, V, N, 13, 300, 10e7)\n",
    "plot_from_ideals(sol_ideals, G, N, geometry, _id)\n",
    "plot_sizes(list(sizes.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Djikstra para limpiar grafo\n",
    "\n",
    "La función distance recibe una fila de un GeoPandas DataFrame. Esta construida la función para que el objeto geométrico a evaluar sea un Linestring. A partir de esto busca retornar la distancia entre estos dos puntos. En caso de que no se pueda, asignará un valor arbitratio previamente definido. En nuestro caso se usó la media del resto de las aristas para determinar este valor. Este procedimiento se describe en la celda siguiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(row, mean_weights):\n",
    "  try:\n",
    "    x_1 = row['geometry'].coords[0][0]\n",
    "    y_1 = row['geometry'].coords[0][1]\n",
    "    x_2 = row['geometry'].coords[1][0]\n",
    "    y_2 = row['geometry'].coords[1][1]\n",
    "    return (x_1 - x_2)**2 + (y_1 - y_2)**2 \n",
    "  except:\n",
    "    return mean_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Código utilizado para filtrar aristas que no correspondían al camino más corto hacia la salida del grafo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leemos archivos\n",
    "path = 'data/graph_geom_corrected_cycles.csv'\n",
    "geometry = gpd.read_file(path, sep = ';', GEOM_POSSIBLE_NAMES=\"geometry\",KEEP_GEOM_COLUMNS=\"NO\" )\n",
    "mean_weights = 3590.47\n",
    "\n",
    "# Instanciamos\n",
    "G = nx.DiGraph()\n",
    "for index, row in geometry.iterrows():\n",
    "  origin = int(row['self'])\n",
    "  dest = int(row['other'])\n",
    "  G.add_edge(origin, dest)\n",
    "  G[origin][dest]['weight'] = distance(row, mean_weights)\n",
    "\n",
    "\n",
    "# Iteramos por todos los nodos para encontrar su camino más corto hacia la salida\n",
    "salida = 1001544; paths = {}; ignored = list()\n",
    "for node in G.nodes:\n",
    "  try:\n",
    "    paths[node] = nx.algorithms.shortest_paths.weighted.single_source_dijkstra(G, node, salida, weight = 'weight')[1]\n",
    "  except:\n",
    "    ignored.append(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = 0 \n",
    "for i in G.edges(data=True):\n",
    "  weights += i[2]['weight']\n",
    "mean_weights = weights / (len(G.edges) - len(ignored))\n",
    "mean_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inicial = geometry.shape[0]\n",
    "dropped = list()\n",
    "for i, row in geometry.iterrows():\n",
    "  origin = int(row['self'])\n",
    "  dest = int(row['other'])\n",
    "  if origin not in ignored:\n",
    "     if dest not in paths[origin]:\n",
    "        geometry = geometry.drop(index = i)\n",
    "        dropped.append(i)\n",
    "  # if origin in ignored:\n",
    "  #   geometry = geometry.drop(index = i)\n",
    "geometry.to_csv('corrected_dijkstra.csv')\n",
    "final = geometry.shape[0]\n",
    "print(f'Se eliminaron {inicial - final} aristas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nodos ignorados\n",
    "path = 'data/graph_geom_corrected_cycles.csv'\n",
    "geometry = gpd.read_file(path, GEOM_POSSIBLE_NAMES=\"geometry\", KEEP_GEOM_COLUMNS=\"NO\")\n",
    "path = 'data/graph_geom_corrected_cycles.csv'\n",
    "csv_grafo = pd.read_csv(path, sep = ';')\n",
    "\n",
    "csv_grafo['color'] = 0\n",
    "\n",
    "for drop in dropped:\n",
    "  csv_grafo.at[drop, 'color'] =  1\n",
    "\n",
    "for ign in ignored:\n",
    "  csv_grafo.loc[csv_grafo['self'] ==  ign , 'color'] = 2\n",
    "  csv_grafo.loc[csv_grafo['other'] ==  ign , 'color'] = 2\n",
    "\n",
    "geometry['color'] = csv_grafo['color'] \n",
    "\n",
    "\n",
    "f, ax = plt.subplots(figsize=(15, 15))\n",
    "ax.set_title(f'Grafo corregido con sus nodos eliminados e ignorados',\n",
    "  fontsize=20)\n",
    "\n",
    "ax = geometry.plot(ax = ax, column = 'color',\n",
    "              figsize=(15, 15),\n",
    "              legend = True,\n",
    "              legend_kwds={'label': \"0: Aristas corregidas \\n 1: Aristas eliminadas \\n 2: Aristas ignoradas\", 'orientation': \"horizontal\"},\n",
    "              cmap = 'brg',)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de sensibilidad de soluciones\n",
    "\n",
    "Se parte instanciando ambos grafos: el original y el corregido. Se definen sus respectivos diccionarios, N y sus grafos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_original = 'data/graph_geom_corrected_cycles.csv'\n",
    "csv_original = pd.read_csv(path_original, sep = ';')\n",
    "geometry_original = gpd.read_file(path_original, GEOM_POSSIBLE_NAMES=\"geometry\", KEEP_GEOM_COLUMNS=\"NO\")\n",
    "path_pesos = 'data/pesos_tapas.csv'\n",
    "pesos = pd.read_csv(path_pesos)\n",
    "\n",
    "\n",
    "S = set()\n",
    "for index, row in csv_original.iterrows():\n",
    "    origin = row['self']\n",
    "    dest = row['other']\n",
    "    S.add(origin)\n",
    "    S.add(dest)\n",
    "\n",
    "S = list(S)\n",
    "id_o = {}; o_id = {}; l = 0\n",
    "for u in S:\n",
    "    id_o[u] = l; o_id[l] = u\n",
    "    l += 1\n",
    "\n",
    "G_original = nx.DiGraph()\n",
    "for index, row in csv_original.iterrows():\n",
    "    origin = row['self']\n",
    "    dest = row['other']\n",
    "    G_original.add_edge(id_o[origin], id_o[dest])\n",
    "    \n",
    "N_o = l\n",
    "\n",
    "W = [0 for u in range(N_o)]\n",
    "V_o = [0 for u in range(N_o)]\n",
    "\n",
    "for u in range(N_o):\n",
    "    if pesos[pesos['ID_tapa'] == _id[u]].shape[0] >= 1:  ## tomamos primera columna con el id, si no hay peso = 0\n",
    "        W[u] = pesos[pesos['ID_tapa'] == _id[u]].iloc[0]['per_predio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_arbol = 'data/corrected_dijkstra.csv'\n",
    "csv_arbol = pd.read_csv(path_arbol)\n",
    "geometry_arbol = gpd.read_file(path_arbol, GEOM_POSSIBLE_NAMES=\"geometry\", KEEP_GEOM_COLUMNS=\"NO\").drop([\"field_1\"], axis=1)\n",
    "\n",
    "S = set()\n",
    "for index, row in csv_arbol.iterrows():\n",
    "    origin = row['self']\n",
    "    dest = row['other']\n",
    "    S.add(origin)\n",
    "    S.add(dest)\n",
    "\n",
    "S = list(S)\n",
    "id_a = {}; a_id = {}; l = 0\n",
    "for u in S:\n",
    "    id_a[u] = l; a_id[l] = u\n",
    "    l += 1\n",
    "\n",
    "G_arbol = nx.DiGraph()\n",
    "for index, row in csv_arbol.iterrows():\n",
    "    origin = row['self']\n",
    "    dest = row['other']\n",
    "    G_arbol.add_edge(id_a[origin], id_a[dest])\n",
    "    \n",
    "N_a = l\n",
    "\n",
    "W_a = [0 for u in range(N_a)]\n",
    "V_a = [0 for u in range(N_a)]\n",
    "\n",
    "for u in range(N_a):\n",
    "    if pesos[pesos['ID_tapa'] == _id[u]].shape[0] >= 1:  ## tomamos primera columna con el id, si no hay peso = 0\n",
    "        W_a[u] = pesos[pesos['ID_tapa'] == _id[u]].iloc[0]['per_predio']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se consideran las primeras 5 etapas. Lo que se hace es para cada etapa se obtienen las soluciones dentro del grafo original. Luego se compara el tamano de los ideales inducidos dentro de los nodos no visitados en ambos grafos y se registra su diferencia. Se calcula su promedio de diferencia porcentual. Además, se filtran los valores que se pasan sobre el 50% del valor del ideal ya que se consideran como datos anómalos. Se comenta procedimiento para la primera etapa. Las siguientes son análogas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_1 = 10; k_2 = 3 \n",
    "k_1 = 8\n",
    "k_2 = 5\n",
    "epsilon = 2\n",
    "# Diferencia porcentual\n",
    "Dif_1 = list(); Dif_2 = list(); Dif_3 = list(); Dif_4 = list(); Dif_5 = list()\n",
    "# Diferencia porcentual excluyendo ideales con diferencias mayores a 0.5 veces el ideal original \n",
    "dif_1 = list(); dif_2 = list(); dif_3 = list(); dif_4 = list(); dif_5 = list()\n",
    "# Diferencia real\n",
    "D1 = list(); D2 = list(); D3 = list(); D4 = list(); D5 = list()\n",
    "# Cantidad de valores filtrados por etapa\n",
    "S1 = 0; S2 = 0; S3 = 0; S4 =0; S5 = 0\n",
    "V_o = [0 for u in range(N_o)]; V_a = [0 for u in range(N_a)]\n",
    "\n",
    "\n",
    "# DESCOMENTAR PARA HACER EL MISMO ANÁLISIS PERO OBTENIENDO LAS SOLUCIONES DESDE EL GRAFO CORREGIDO\n",
    "\n",
    "# G_arbol, G_original = G_original, G_arbol\n",
    "# V_o, V_a = V_a, V_o\n",
    "# N_o, N_a = N_a, N_o\n",
    "# o_id, a_id = a_id, o_id\n",
    "# id_a, id_o = id_o, id_a\n",
    "\n",
    "# PRIMERA ETAPA\n",
    "# Primero obtenemos la solución\n",
    "ans_o, sol_dict_o, sizes_o, sol_ideals_o = greedyAppWeightReduceDynamic_partition(G_original, V_o, N_o, k_1, 400, 10e7)\n",
    "# Para cada elemento de la solución definimos el ideal correspondiente dentro del grafo corregido.\n",
    "for sol_o, ideal_o in sol_ideals_o.items():\n",
    "        sol_a = id_a[o_id[sol_o]]\n",
    "        size_o = get_size(G_original, V_o, N_o, sol_o)\n",
    "        # Calculamos la diferencia del tamano de los ideales en ambos grafos.\n",
    "        d1 = abs(get_size(G_arbol, V_a, N_a, sol_a) - size_o)\n",
    "        D1.append(d1)\n",
    "        # Si cumple el filtro lo agregamos a la lista que registra las diferencias  relativas\n",
    "        if d1 < size_o * 0.5 + epsilon:\n",
    "            dif_1.append(d1 / size_o)\n",
    "            Dif_1.append(d1 / size_o)\n",
    "        else:\n",
    "             # En caso contrario registramos que lo hemos ignorado\n",
    "            S1 += 1\n",
    "            Dif_1.append(d1 / size_o)\n",
    "\n",
    "        \n",
    "        # SEGUNDA ETAPA\n",
    "        # Agregamos el paso de volver a calcular la lista de visitados para trabajar solamente dentro de este ideal\n",
    "        V_o_2 = [0 if i in ideal_o else 1 for i in range(N_o)]\n",
    "        ideal_a = [id_a[o_id[i]] for i in ideal_o] \n",
    "        V_a_2 = [0 if i in ideal_a else 1 for i in range(N_a)] \n",
    "        ans_o_2, sol_dict_o_2, sizes_o_2, sol_ideals_o_2 = greedyAppWeightReduceDynamic_partition(G_original, V_o_2, N_o, k_2, 75, 10e7)\n",
    "        for sol_o, ideal_o in sol_ideals_o_2.items():\n",
    "            sol_a = id_a[o_id[sol_o]]\n",
    "            size_o = get_size(G_original, V_o_2, N_o, sol_o)\n",
    "            d2 = abs(get_size(G_arbol, V_a_2, N_a, sol_a) - size_o)\n",
    "            D2.append(d2)\n",
    "            if d2 < size_o * 0.5 + epsilon:\n",
    "                dif_2.append(d2 / size_o)\n",
    "                Dif_2.append(d2 / size_o)\n",
    "            else:\n",
    "                S2 += 1\n",
    "                Dif_2.append(d2 / size_o)\n",
    "\n",
    "            \n",
    "            # TERCERA ETAPA\n",
    "            V_o_3 = [0 if i in ideal_o else 1 for i in range(N_o)]\n",
    "            ideal_a = [id_a[o_id[i]] for i in ideal_o] \n",
    "            V_a_3 = [0 if i in ideal_a else 1 for i in range(N_a)] \n",
    "            ans_o_3, sol_dict_o_3, sizes_o_3, sol_ideals_o_3 = greedyAppWeightReduceDynamic_partition(G_original, V_o_3, N_o, k_2, 20, 10e7)\n",
    "            for sol_o, ideal_o in sol_ideals_o_3.items():\n",
    "                sol_a = id_a[o_id[sol_o]]\n",
    "                size_o = get_size(G_original, V_o_3, N_o, sol_o)\n",
    "                d3 = abs(get_size(G_arbol, V_a_3, N_a, sol_a) - size_o)\n",
    "                D3.append(d3)\n",
    "                if d3 < size_o * 0.5 + epsilon:\n",
    "                    dif_3.append(d3 / size_o)\n",
    "                    Dif_3.append(d3 / size_o)\n",
    "                else:\n",
    "                    S3 += 1\n",
    "                    Dif_3.append(d3 / size_o)\n",
    "             \n",
    "                \n",
    "                # CUARTA ETAPA\n",
    "                V_o_4 = [0 if i in ideal_o else 1 for i in range(N_o)]\n",
    "                ideal_a = [id_a[o_id[i]] for i in ideal_o] \n",
    "                V_a_4 = [0 if i in ideal_a else 1 for i in range(N_a)] \n",
    "                ans_o_4, sol_dict_o_4, sizes_o_4, sol_ideals_o_4 = greedyAppWeightReduceDynamic_partition(G_original, V_o_4, N_o, k_2, 10, 10e7)\n",
    "                for sol_o, ideal_o in sol_ideals_o_4.items():\n",
    "                    sol_a = id_a[o_id[sol_o]]\n",
    "                    size_o = get_size(G_original, V_o_4, N_o, sol_o)\n",
    "                    d4 = abs(get_size(G_arbol, V_a_4, N_a, sol_a) - size_o)\n",
    "                    D4.append(d4)\n",
    "                    if d4 < size_o * 0.5 + epsilon:\n",
    "                        dif_4.append(d4 / size_o)\n",
    "                        Dif_4.append(d4 / size_o)\n",
    "                    else:\n",
    "                        S4 += 1\n",
    "                        Dif_4.append(d4 / size_o)\n",
    "\n",
    "                    \n",
    "                    # QUINTA ETAPA\n",
    "                    V_o_5 = [0 if i in ideal_o else 1 for i in range(N_o)]\n",
    "                    ideal_a = [id_a[o_id[i]] for i in ideal_o] \n",
    "                    V_a_5 = [0 if i in ideal_a else 1 for i in range(N_a)] \n",
    "                    ans_o_5, sol_dict_o_5, sizes_o_5, sol_ideals_o_5 = greedyAppWeightReduceDynamic_partition(G_original, V_o_5, N_o, k_2, 2, 10e7)\n",
    "                    for sol_o, ideal_o in sol_ideals_o_5.items():\n",
    "                        sol_a = id_a[o_id[sol_o]]\n",
    "                        size_o = get_size(G_original, V_o_5, N_o, sol_o)\n",
    "                        d5 = abs(get_size(G_arbol, V_a_5, N_a, sol_a) - size_o)\n",
    "                        D5.append(d5)\n",
    "                        if d5 < size_o * 0.5 + epsilon:\n",
    "                            dif_5.append(d5 / size_o)\n",
    "                            Dif_5.append(d5 / size_o)\n",
    "                        else:\n",
    "                            S5 += 1\n",
    "                            Dif_5.append(d5 / size_o)\n",
    "                       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'ETAPA 1 -> Ignorados: {S1}, promedio sin ignorar: {round(sum(Dif_1) / len(Dif_1), 4)*100}% promedio ignorando: {round(sum(dif_1) / len(dif_1), 4)*100}%')\n",
    "print(f'ETAPA 1 -> Ignorados: {S2}, promedio sin ignorar: {round(sum(Dif_2) / len(Dif_2), 4)*100}% promedio ignorando: {round(sum(dif_2) / len(dif_2), 4)*100}%')\n",
    "print(f'ETAPA 1 -> Ignorados: {S3}, promedio sin ignorar: {round(sum(Dif_3) / len(Dif_3), 4)*100}% promedio ignorando: {round(sum(dif_3) / len(dif_3), 4)*100}%')\n",
    "print(f'ETAPA 1 -> Ignorados: {S4}, promedio sin ignorar: {round(sum(Dif_4) / len(Dif_4), 4)*100}% promedio ignorando: {round(sum(dif_4) / len(dif_4), 4)*100}%')\n",
    "print(f'ETAPA 1 -> Ignorados: {S5}, promedio sin ignorar: {round(sum(Dif_5) / len(Dif_5), 4)*100}% promedio ignorando: {round(sum(dif_5) / len(dif_5), 4)*100}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
